\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{float}
\usepackage{longtable}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Unsupervised Music Genre Discovery Using Audio Feature Learning: A Comprehensive Multi-Dataset Analysis}

\author{
\IEEEauthorblockN{Anirudh Sharma}
\IEEEauthorblockA{\textit{Department of Computer Science and Engineering} \\
\textit{University Name}\\
Roll No: [Your Roll Number]\\
Email: your.email@university.edu}
}

\maketitle

\begin{abstract}
This research presents a comprehensive investigation into unsupervised music genre discovery using audio feature learning across four diverse datasets: GTZAN (1,000 tracks), Free Music Archive (FMA, 6,410 tracks), Million Song Dataset (MSD, 100 tracks), and Spotify Music Dataset (116,724 tracks). We implemented and evaluated five clustering algorithms—K-Means, MiniBatch K-Means, Spectral Clustering, Gaussian Mixture Models (GMM), and DBSCAN—using multiple train-test splits (50-50, 60-40, 70-30, 80-20) to assess performance stability. Our analysis employed six evaluation metrics including Silhouette Score, Davies-Bouldin Index, Calinski-Harabasz Index, Normalized Mutual Information (NMI), Adjusted Rand Index (ARI), and clustering accuracy. Results demonstrate that K-Means and Spectral Clustering consistently achieve superior performance across datasets, with the GTZAN dataset yielding the highest accuracy (45\%) and NMI (0.4648) at an 80-20 split. The Spotify dataset, despite its large scale (116,724 tracks after cleaning), achieved competitive results with K-Means attaining a Silhouette Score of 0.1087. Statistical analysis revealed significant feature correlations and distribution patterns critical for genre classification. This work contributes empirical evidence for the effectiveness of unsupervised learning in music information retrieval and provides practical insights for real-world music recommendation systems.
\end{abstract}

\begin{IEEEkeywords}
Music Genre Classification, Unsupervised Learning, Clustering Algorithms, Audio Feature Extraction, Music Information Retrieval
\end{IEEEkeywords}

\section{Introduction}

Music genre classification represents a fundamental challenge in Music Information Retrieval (MIR), with applications spanning digital music libraries, recommendation systems, and automated playlist generation. Traditional supervised approaches require extensive labeled datasets, which are expensive and time-consuming to create. This research explores unsupervised learning techniques for automatic music genre discovery, eliminating the need for manual annotation while uncovering inherent patterns in audio features.

\subsection{Motivation}

The exponential growth of digital music collections necessitates automated organization and retrieval systems. With millions of tracks available across streaming platforms, unsupervised genre discovery offers several advantages:

\begin{itemize}
    \item \textbf{Scalability:} No requirement for labeled training data
    \item \textbf{Flexibility:} Adaptable to evolving music styles and emerging genres
    \item \textbf{Discovery:} Potential to identify previously unrecognized genre patterns
    \item \textbf{Cost-effectiveness:} Eliminates expensive manual labeling processes
\end{itemize}

\subsection{Research Objectives}

This study aims to:

\begin{enumerate}
    \item Conduct comprehensive data quality analysis across four diverse music datasets
    \item Extract and analyze audio features including MFCCs, spectral features, and temporal characteristics
    \item Implement and compare five state-of-the-art clustering algorithms
    \item Evaluate performance across multiple train-test configurations
    \item Identify optimal clustering strategies for music genre discovery
    \item Provide empirical insights for practical music recommendation systems
\end{enumerate}

\subsection{Contributions}

Our key contributions include:

\begin{itemize}
    \item Extensive multi-dataset evaluation (12,234 total tracks across four datasets)
    \item Comprehensive statistical analysis with robust methods (trimmed statistics, outlier detection)
    \item Multiple train-test split experiments (50-50, 60-40, 70-30, 80-20)
    \item Six evaluation metrics per experiment for thorough assessment
    \item Comparative analysis identifying dataset-specific performance characteristics
    \item Open-source implementation with reproducible results
\end{itemize}

\section{Related Work}

Music genre classification has been extensively studied using both supervised and unsupervised approaches. Tzanetakis and Cook \cite{tzanetakis2002} introduced the GTZAN dataset and demonstrated genre classification using timbral and rhythmic features. Li et al. \cite{li2003} explored comparative music similarity measures, while Mandel and Ellis \cite{mandel2005} investigated automatic music similarity judgment using web-based data.

Unsupervised approaches for music analysis have shown promising results. Hoffman et al. \cite{hoffman2009} applied topic models to music, while McFee and Lanckriet \cite{mcfee2012} explored heterogeneous embeddings for subjective music similarity. Recent work by van den Oord et al. \cite{oord2013} demonstrated deep content-based music recommendation.

Our work extends previous research by providing comprehensive multi-dataset evaluation with robust statistical analysis and multiple clustering algorithms under various experimental configurations.

\section{Datasets}

We analyzed four distinct music datasets, each offering unique characteristics and challenges.

\subsection{GTZAN Dataset}

\textbf{Overview:} The GTZAN Genre Collection is a widely-used benchmark dataset for music genre classification research.

\begin{itemize}
    \item \textbf{Total Tracks:} 1,000
    \item \textbf{Genres:} 10 (blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, rock)
    \item \textbf{Samples per Genre:} 100 (perfectly balanced)
    \item \textbf{Features Extracted:} 58 audio features
    \item \textbf{Track Length:} 30 seconds each
    \item \textbf{Data Quality:} Complete (0 missing values)
\end{itemize}

\textbf{Adequacy Assessment:}
\begin{itemize}
    \item Sample-to-Feature Ratio: 17.24 (✓ ADEQUATE)
    \item Class Balance Ratio: 1.00 (Perfect balance)
    \item Outliers: 60.2\% removed using IQR method
    \item Final Samples: 398 after cleaning
\end{itemize}

\subsection{Free Music Archive (FMA) Dataset}

\textbf{Overview:} FMA provides a large-scale dataset with diverse music genres and comprehensive metadata.

\begin{itemize}
    \item \textbf{Total Tracks:} 6,410 (processed from FMA-Small subset)
    \item \textbf{Genres:} 8 (Electronic, Experimental, Folk, Hip-Hop, Instrumental, International, Pop, Rock)
    \item \textbf{Features Extracted:} 155 (MFCCs, Delta-MFCCs, Delta²-MFCCs, Chroma, Spectral)
    \item \textbf{Processing Time:} ~46 minutes
    \item \textbf{Final Samples:} 2,091 after outlier removal (67.38\% removed)
\end{itemize}

\textbf{Feature Breakdown:}
\begin{itemize}
    \item MFCCs: 40 features (mean + std for 20 coefficients)
    \item Delta-MFCCs: 40 features (temporal dynamics)
    \item Delta²-MFCCs: 40 features (acceleration)
    \item Chroma: 24 features (pitch class profiles)
    \item Spectral: 6 features (centroid, rolloff, bandwidth)
    \item Other: 5 features (tempo, zero-crossing rate, etc.)
\end{itemize}

\subsection{Million Song Dataset (MSD)}

\textbf{Overview:} A subset of the Million Song Dataset providing comprehensive audio feature metadata in HDF5 format.

\begin{itemize}
    \item \textbf{Total Tracks:} 100 (demonstration subset)
    \item \textbf{Features Extracted:} 134 (131 numeric + 3 metadata)
    \item \textbf{Format:} HDF5 files with pre-computed features
    \item \textbf{Feature Types:} Timbre (60), Pitch (60), Basic audio (11), Metadata (3)
\end{itemize}

\subsection{Spotify Music Dataset}

\textbf{Overview:} Large-scale dataset from Spotify's API containing track-level audio features and metadata.

\begin{itemize}
    \item \textbf{Original Tracks:} 170,653
    \item \textbf{After Cleaning:} 116,724
    \item \textbf{Duplicates Removed:} 4,454 (2.61\%)
    \item \textbf{Outliers Removed:} 49,475 (29.77\%)
    \item \textbf{Features Analyzed:} 13 audio features
    \item \textbf{Feature Types:} Danceability, Energy, Loudness, Speechiness, Acousticness, Instrumentalness, Liveness, Valence, Tempo, Duration, Time Signature, Key, Mode
\end{itemize}

\section{Methodology}

\subsection{Data Preprocessing Pipeline}

Our data preprocessing pipeline consists of four stages:

\subsubsection{Stage 1: Data Collection and Loading}
\begin{itemize}
    \item Load raw audio files or feature datasets
    \item Verify data integrity and format
    \item Extract metadata (track ID, artist, genre labels if available)
\end{itemize}

\subsubsection{Stage 2: Quality Assessment}
\begin{itemize}
    \item Check for missing values
    \item Assess dataset adequacy (sample-to-feature ratio)
    \item Evaluate class balance/distribution
    \item Identify data quality issues
\end{itemize}

\subsubsection{Stage 3: Feature Extraction}
For GTZAN and FMA datasets (audio files):
\begin{itemize}
    \item Extract MFCCs (Mel-Frequency Cepstral Coefficients)
    \item Compute spectral features (centroid, rolloff, bandwidth)
    \item Calculate temporal features (zero-crossing rate, RMS energy)
    \item Extract chromagram features
    \item Compute statistical summaries (mean, variance, min, max)
\end{itemize}

For MSD and Spotify datasets (pre-computed features):
\begin{itemize}
    \item Load pre-computed feature vectors
    \item Validate feature completeness
    \item Normalize feature ranges
\end{itemize}

\subsubsection{Stage 4: Data Cleaning}
\begin{itemize}
    \item \textbf{Missing Value Handling:} Replace with column mean or remove incomplete samples
    \item \textbf{Outlier Detection:} IQR method with 1.5 threshold
    \item \textbf{Outlier Removal:} Remove samples beyond IQR bounds
    \item \textbf{Normalization:} StandardScaler for zero mean and unit variance
    \item \textbf{Dimensionality Reduction:} PCA for visualization (optional)
\end{itemize}

\subsection{Statistical Analysis}

We conducted comprehensive statistical analysis following course requirements:

\subsubsection{Descriptive Statistics}
For each dataset, we computed:
\begin{itemize}
    \item Sample mean ($\bar{X}$)
    \item Median ($M$)
    \item Standard deviation ($\sigma$)
    \item Variance ($\sigma^2$)
    \item Skewness and kurtosis
    \item Range and interquartile range (IQR)
\end{itemize}

\subsubsection{Percentile and Quartile Analysis}
\begin{itemize}
    \item 25th percentile ($Q_1$)
    \item 50th percentile (Median, $M$)
    \item 75th percentile ($Q_3$)
    \item Interquartile range: $IQR = Q_3 - Q_1$
\end{itemize}

\subsubsection{Trimmed Statistics}
To eliminate outlier influence:
\begin{itemize}
    \item 10\% trimming from each distribution end
    \item Trimmed mean ($\bar{X}_T$)
    \item Trimmed median ($M_T$)
    \item Trimmed standard deviation ($S_T$)
\end{itemize}

\subsubsection{Correlation Analysis}
\begin{itemize}
    \item Pearson correlation matrix for all feature pairs
    \item Identification of highly correlated features
    \item Correlation heatmap visualization
\end{itemize}

\subsubsection{Distribution Analysis}
\begin{itemize}
    \item Normality testing (Shapiro-Wilk test where applicable)
    \item Distribution visualization (histograms, KDE plots)
    \item Box plots for outlier identification
\end{itemize}

\subsection{Clustering Algorithms}

We implemented five clustering algorithms with optimized parameters:

\subsubsection{K-Means Clustering}
\begin{itemize}
    \item \textbf{Algorithm:} Centroid-based partitioning
    \item \textbf{Parameters:} k=10 clusters, max\_iter=300, n\_init=10
    \item \textbf{Initialization:} k-means++
    \item \textbf{Advantages:} Fast, scalable, interpretable
    \item \textbf{Limitations:} Assumes spherical clusters, sensitive to initialization
\end{itemize}

\subsubsection{MiniBatch K-Means}
\begin{itemize}
    \item \textbf{Algorithm:} Batch-based K-Means variant
    \item \textbf{Parameters:} k=10, batch\_size=100, max\_iter=300
    \item \textbf{Advantages:} Faster for large datasets, reduced memory usage
    \item \textbf{Limitations:} Slightly lower accuracy than standard K-Means
\end{itemize}

\subsubsection{Spectral Clustering}
\begin{itemize}
    \item \textbf{Algorithm:} Graph-based clustering using eigenvalues
    \item \textbf{Parameters:} k=10, affinity='rbf', gamma=1.0
    \item \textbf{Advantages:} Handles non-convex clusters, captures complex structures
    \item \textbf{Limitations:} Computationally expensive, memory-intensive
\end{itemize}

\subsubsection{Gaussian Mixture Models (GMM)}
\begin{itemize}
    \item \textbf{Algorithm:} Probabilistic model-based clustering
    \item \textbf{Parameters:} n\_components=10, covariance\_type='full'
    \item \textbf{Advantages:} Soft clustering, models uncertainty, flexible cluster shapes
    \item \textbf{Limitations:} Sensitive to initialization, may converge to local optima
\end{itemize}

\subsubsection{DBSCAN}
\begin{itemize}
    \item \textbf{Algorithm:} Density-based spatial clustering
    \item \textbf{Parameters:} eps (auto-tuned using k-distance), min\_samples=5
    \item \textbf{Advantages:} Discovers arbitrary-shaped clusters, handles noise
    \item \textbf{Limitations:} Sensitive to eps parameter, struggles with varying densities
\end{itemize}

\subsection{Experimental Configuration}

\subsubsection{Train-Test Splits}
We evaluated each algorithm using four different splits:
\begin{enumerate}
    \item 50-50: 50\% training, 50\% testing
    \item 60-40: 60\% training, 40\% testing
    \item 70-30: 70\% training, 30\% testing
    \item 80-20: 80\% training, 20\% testing
\end{enumerate}

\subsubsection{Cross-Validation}
\begin{itemize}
    \item Random shuffling with fixed random seed for reproducibility
    \item Multiple runs to assess stability
    \item Stratified sampling where applicable
\end{itemize}

\subsection{Evaluation Metrics}

We employed six evaluation metrics to comprehensively assess clustering performance:

\subsubsection{Silhouette Score}
\begin{equation}
s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}
\end{equation}
where $a(i)$ is the mean intra-cluster distance and $b(i)$ is the mean nearest-cluster distance. Range: [-1, 1], higher is better.

\subsubsection{Davies-Bouldin Index}
\begin{equation}
DB = \frac{1}{k}\sum_{i=1}^{k}\max_{j \neq i}\left(\frac{\sigma_i + \sigma_j}{d(c_i, c_j)}\right)
\end{equation}
where $\sigma_i$ is the average distance within cluster $i$ and $d(c_i, c_j)$ is the distance between centroids. Lower is better.

\subsubsection{Calinski-Harabasz Index}
\begin{equation}
CH = \frac{tr(B_k)}{tr(W_k)} \times \frac{n - k}{k - 1}
\end{equation}
where $B_k$ is between-cluster dispersion and $W_k$ is within-cluster dispersion. Higher is better.

\subsubsection{Normalized Mutual Information (NMI)}
\begin{equation}
NMI(U, V) = \frac{2 \times I(U; V)}{H(U) + H(V)}
\end{equation}
where $I(U; V)$ is mutual information and $H$ is entropy. Range: [0, 1], higher is better.

\subsubsection{Adjusted Rand Index (ARI)}
\begin{equation}
ARI = \frac{RI - E[RI]}{\max(RI) - E[RI]}
\end{equation}
Range: [-1, 1], where 1 indicates perfect agreement, 0 indicates random labeling.

\subsubsection{Clustering Accuracy}
\begin{equation}
Accuracy = \frac{\sum_{i=1}^{k}\max_j|c_i \cap g_j|}{n}
\end{equation}
where $c_i$ are predicted clusters and $g_j$ are ground truth genres. Range: [0, 1].

\section{Results and Discussion}

\subsection{GTZAN Dataset Results}

The GTZAN dataset demonstrated the strongest overall performance among all datasets.

\subsubsection{Statistical Analysis}

Table \ref{tab:gtzan_stats} presents key statistical findings:

\begin{table}[H]
\centering
\caption{GTZAN Dataset - Statistical Summary}
\label{tab:gtzan_stats}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Value} & \textbf{Status} \\
\midrule
Total Samples & 1,000 & \\
Features & 58 & \\
Sample-to-Feature Ratio & 17.24 & ✓ Adequate \\
Class Balance Ratio & 1.00 & Perfect \\
Missing Values & 0 & ✓ Complete \\
Outliers Removed & 602 (60.2\%) & \\
Final Samples & 398 & \\
Normal Distributions & 1 (1.72\%) & \\
Non-Normal Distributions & 57 (98.28\%) & \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Correlations:} The strongest feature correlations observed were:
\begin{itemize}
    \item Spectral Centroid $\leftrightarrow$ Rolloff: 0.9796
    \item Spectral Bandwidth $\leftrightarrow$ Rolloff: 0.9562
    \item Spectral Centroid $\leftrightarrow$ MFCC2: -0.9402
\end{itemize}

\subsubsection{Clustering Performance}

Table \ref{tab:gtzan_clustering} presents comprehensive clustering results across all splits:

\begin{table*}[htbp]
\centering
\caption{GTZAN Dataset - Clustering Performance Across Train-Test Splits}
\label{tab:gtzan_clustering}
\small
\begin{tabular}{llcccccccc}
\toprule
\textbf{Split} & \textbf{Algorithm} & \textbf{Silh.} & \textbf{DB} & \textbf{CH} & \textbf{NMI} & \textbf{ARI} & \textbf{V-Meas.} & \textbf{Acc.} & \textbf{Samples} \\
\midrule
\multirow{4}{*}{50-50} 
& K-Means & 0.1303 & 1.8857 & 23.75 & 0.3923 & 0.1573 & 0.3923 & 0.402 & 199 \\
& MiniBatch K-Means & 0.1221 & 1.8133 & 22.57 & 0.3406 & 0.1387 & 0.3406 & 0.377 & 199 \\
& Spectral & 0.1223 & 1.8364 & 22.72 & 0.4144 & 0.1783 & 0.4144 & 0.397 & 199 \\
& GMM & 0.1179 & 2.0476 & 22.92 & 0.3929 & 0.1525 & 0.3929 & 0.382 & 199 \\
\midrule
\multirow{4}{*}{60-40} 
& K-Means & 0.1251 & 1.8929 & 19.50 & 0.4389 & 0.1973 & 0.4389 & 0.431 & 160 \\
& MiniBatch K-Means & 0.1178 & 1.8663 & 18.62 & 0.4408 & 0.1861 & 0.4408 & 0.444 & 160 \\
& Spectral & 0.1281 & 1.7977 & 19.38 & 0.4478 & 0.2001 & 0.4478 & \textbf{0.444} & 160 \\
& GMM & 0.1293 & 1.7467 & 17.60 & 0.4483 & 0.1898 & 0.4483 & \textbf{0.450} & 160 \\
\midrule
\multirow{4}{*}{70-30} 
& K-Means & 0.1244 & 1.7997 & 15.05 & 0.3774 & 0.1234 & 0.3774 & 0.375 & 120 \\
& MiniBatch K-Means & 0.1198 & 1.8430 & 14.91 & 0.4207 & 0.1601 & 0.4207 & 0.442 & 120 \\
& Spectral & 0.1209 & 1.8070 & 14.48 & 0.4393 & 0.1597 & 0.4393 & 0.408 & 120 \\
& GMM & 0.1244 & 1.7997 & 15.05 & 0.3774 & 0.1234 & 0.3774 & 0.375 & 120 \\
\midrule
\multirow{4}{*}{80-20} 
& K-Means & 0.1165 & 1.7875 & 9.70 & \textbf{0.4648} & 0.1381 & \textbf{0.4648} & 0.375 & 80 \\
& MiniBatch K-Means & \textbf{0.1356} & \textbf{1.5265} & 9.35 & 0.4592 & 0.1353 & 0.4592 & 0.400 & 80 \\
& Spectral & 0.1219 & 1.5527 & \textbf{9.66} & 0.4502 & \textbf{0.1410} & 0.4502 & \textbf{0.450} & 80 \\
& GMM & 0.1165 & 1.7875 & 9.70 & \textbf{0.4648} & 0.1381 & \textbf{0.4648} & 0.375 & 80 \\
\bottomrule
\end{tabular}
\end{table*}

\textbf{Best Results:}
\begin{itemize}
    \item \textbf{Highest Accuracy:} 45.0\% (GMM, 60-40 split)
    \item \textbf{Highest NMI:} 0.4648 (K-Means/GMM, 80-20 split)
    \item \textbf{Highest Silhouette:} 0.1356 (MiniBatch K-Means, 80-20 split)
    \item \textbf{Lowest DB Index:} 1.5265 (MiniBatch K-Means, 80-20 split)
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_GTZAN/output/results/correlation_heatmap.png}
\caption{GTZAN - Feature Correlation Heatmap}
\label{fig:gtzan_corr}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_GTZAN/output/results/distribution_analysis.png}
\caption{GTZAN - Feature Distribution Analysis}
\label{fig:gtzan_dist}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_GTZAN/output/results/outlier_boxplots.png}
\caption{GTZAN - Outlier Detection Using Box Plots}
\label{fig:gtzan_boxplot}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_GTZAN/output/results/metrics_comparison.png}
\caption{GTZAN - Clustering Metrics Comparison}
\label{fig:gtzan_metrics}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_GTZAN/output/results/performance_by_split.png}
\caption{GTZAN - Performance Across Train-Test Splits}
\label{fig:gtzan_splits}
\end{figure}

\subsection{Free Music Archive (FMA) Dataset Results}

The FMA dataset, being the largest in terms of processed audio files (6,410 tracks), provided insights into scalability challenges.

\subsubsection{Statistical Overview}

\begin{table}[H]
\centering
\caption{FMA Dataset - Statistical Summary}
\label{tab:fma_stats}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Total Files Processed & 6,410 \\
Features Extracted & 155 \\
Processing Time & ~46 minutes \\
Outliers Removed & 4,319 (67.38\%) \\
Final Samples & 2,091 \\
Genres & 8 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Algorithm Performance Ranking}

\begin{table}[H]
\centering
\caption{FMA Dataset - Algorithm Rankings (Average Across All Splits)}
\label{tab:fma_ranking}
\small
\begin{tabular}{clcccc}
\toprule
\textbf{Rank} & \textbf{Algorithm} & \textbf{Purity} & \textbf{Accuracy} & \textbf{NMI} & \textbf{ARI} \\
\midrule
1 & Spectral & 36.10\% & 31.87\% & 0.1393 & 0.0881 \\
2 & K-Means & 34.40\% & 29.07\% & 0.1283 & 0.0758 \\
3 & GMM & 34.08\% & 29.23\% & 0.1125 & 0.0817 \\
4 & MiniBatch K-Means & 33.92\% & 29.14\% & 0.1244 & 0.0782 \\
5 & DBSCAN & 25.12\% & 25.12\% & 0.0000 & 0.0000 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Best Individual Results:}
\begin{itemize}
    \item \textbf{Purity:} 37.00\% (K-Means, 60-40 split)
    \item \textbf{Accuracy:} 32.60\% (Spectral, 80-20 split)
    \item \textbf{NMI:} 0.1414 (Spectral, 70-30 split)
    \item \textbf{ARI:} 0.1019 (GMM, 80-20 split)
    \item \textbf{Silhouette:} 0.0797 (MiniBatch K-Means, 80-20 split)
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_FMD/output/results/correlation_matrix.png}
\caption{FMA - Feature Correlation Matrix}
\label{fig:fma_corr}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_FMD/output/results/distributions.png}
\caption{FMA - Feature Distributions}
\label{fig:fma_dist}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_FMD/output/results/boxplots.png}
\caption{FMA - Box Plots for Outlier Detection}
\label{fig:fma_boxplot}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_FMD/output/results/accuracy_comparison.png}
\caption{FMA - Accuracy Comparison Across Algorithms}
\label{fig:fma_acc}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_FMD/output/results/silhouette_comparison.png}
\caption{FMA - Silhouette Score Comparison}
\label{fig:fma_silh}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_FMD/output/results/nmi_comparison.png}
\caption{FMA - NMI Comparison Across Splits}
\label{fig:fma_nmi}
\end{figure}

\subsection{Million Song Dataset (MSD) Results}

The MSD subset (100 songs) demonstrated challenges with smaller sample sizes.

\subsubsection{Clustering Results}

\begin{table}[H]
\centering
\caption{MSD Dataset - Clustering Performance}
\label{tab:msd_results}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Algorithm} & \textbf{Silhouette} & \textbf{DB Index} & \textbf{CH Index} & \textbf{Clusters} \\
\midrule
K-Means & 0.0657 & 1.8500 & 6.559 & 10 \\
MiniBatch K-Means & 0.0600 & 2.0527 & 6.262 & 10 \\
Spectral & 0.0486 & 2.2233 & 6.293 & 10 \\
GMM & \textbf{0.0670} & 2.0632 & \textbf{6.441} & 10 \\
DBSCAN & --- & --- & --- & 0* \\
\bottomrule
\multicolumn{5}{l}{\small *DBSCAN failed to form clusters (all noise points)} \\
\end{tabular}
\end{table}

\textbf{Observations:}
\begin{itemize}
    \item GMM achieved the best Silhouette Score (0.0670)
    \item K-Means showed the best Davies-Bouldin Index (1.8500)
    \item Small sample size limited performance
    \item DBSCAN struggled with the high-dimensional feature space
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_MSD/output/plots/correlation_heatmap.png}
\caption{MSD - Correlation Heatmap}
\label{fig:msd_corr}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_MSD/output/plots/distributions.png}
\caption{MSD - Feature Distributions}
\label{fig:msd_dist}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_MSD/output/plots/boxplots.png}
\caption{MSD - Box Plots}
\label{fig:msd_boxplot}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_MSD/output/plots/tsne_visualization.png}
\caption{MSD - t-SNE Visualization of Clusters}
\label{fig:msd_tsne}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_MSD/output/plots/metrics_comparison.png}
\caption{MSD - Metrics Comparison}
\label{fig:msd_metrics}
\end{figure}

\subsection{Spotify Dataset Results}

The Spotify dataset, with 116,724 tracks after cleaning, represents the largest-scale analysis.

\subsubsection{Data Cleaning Impact}

\begin{table}[H]
\centering
\caption{Spotify Dataset - Data Cleaning Summary}
\label{tab:spotify_cleaning}
\begin{tabular}{lcc}
\toprule
\textbf{Stage} & \textbf{Count} & \textbf{Percentage} \\
\midrule
Original Tracks & 170,653 & 100\% \\
Duplicates Removed & 4,454 & 2.61\% \\
Outliers Removed & 49,475 & 29.77\% \\
Final Dataset & 116,724 & 68.41\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Clustering Performance}

\begin{table}[H]
\centering
\caption{Spotify Dataset - Best Clustering Results (K-Means)}
\label{tab:spotify_results}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Silhouette Score & 0.1087 \\
Davies-Bouldin Index & 1.8903 \\
Calinski-Harabasz Index & 10,065.59 \\
Number of Clusters & 10 \\
Inertia & 854,315.98 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_SPOTIFY/visualizations/correlation_heatmap.png}
\caption{Spotify - Feature Correlation Heatmap}
\label{fig:spotify_corr}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_SPOTIFY/visualizations/feature_distributions.png}
\caption{Spotify - Feature Distributions}
\label{fig:spotify_dist}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_SPOTIFY/visualizations/box_plots.png}
\caption{Spotify - Box Plots}
\label{fig:spotify_boxplot}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_SPOTIFY/output/results/clustering_comparison.png}
\caption{Spotify - Clustering Algorithm Comparison}
\label{fig:spotify_clustering}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_SPOTIFY/output/results/train_test_experiments.png}
\caption{Spotify - Train-Test Split Experiments}
\label{fig:spotify_splits}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{GENERE_SPOTIFY/output/results/clustering_pca_visualization.png}
\caption{Spotify - PCA Visualization of Clusters}
\label{fig:spotify_pca}
\end{figure}

\subsection{Cross-Dataset Comparison}

\begin{table*}[htbp]
\centering
\caption{Comparative Performance Across Datasets}
\label{tab:cross_dataset}
\small
\begin{tabular}{lcccccccc}
\toprule
\textbf{Dataset} & \textbf{Tracks} & \textbf{Features} & \textbf{Genres} & \textbf{Best Algo} & \textbf{Max Acc.} & \textbf{Max NMI} & \textbf{Max Silh.} & \textbf{Best Split} \\
\midrule
GTZAN & 1,000 (398) & 58 & 10 & GMM/Spectral & \textbf{45.0\%} & \textbf{0.4648} & 0.1356 & 60-40/80-20 \\
FMA & 6,410 (2,091) & 155 & 8 & Spectral & 32.6\% & 0.1414 & 0.0797 & 70-30/80-20 \\
MSD & 100 & 134 & --- & GMM & --- & --- & 0.0670 & --- \\
Spotify & 170,653 (116,724) & 13 & --- & K-Means & --- & --- & \textbf{0.1087} & --- \\
\bottomrule
\multicolumn{9}{l}{\small Numbers in parentheses indicate final sample count after cleaning} \\
\end{tabular}
\end{table*}

\textbf{Key Insights:}
\begin{itemize}
    \item \textbf{GTZAN} achieved the best overall performance due to balanced classes and moderate feature dimensionality
    \item \textbf{FMA} demonstrated scalability but with reduced accuracy due to increased complexity
    \item \textbf{MSD} struggled with small sample size relative to feature dimensionality
    \item \textbf{Spotify} showed competitive results despite very large scale, benefiting from well-curated features
\end{itemize}

\subsection{Algorithm Performance Summary}

\begin{table}[H]
\centering
\caption{Overall Algorithm Rankings Across All Datasets}
\label{tab:algo_overall}
\begin{tabular}{clc}
\toprule
\textbf{Rank} & \textbf{Algorithm} & \textbf{Best For} \\
\midrule
1 & K-Means & Balanced datasets, speed \\
2 & Spectral Clustering & Complex patterns, FMA \\
3 & GMM & GTZAN, probabilistic assignments \\
4 & MiniBatch K-Means & Large-scale, efficiency \\
5 & DBSCAN & Noise detection (limited success) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Feature Importance Analysis}

Across all datasets, the following features demonstrated strong discriminative power:

\textbf{Spectral Features:}
\begin{itemize}
    \item Spectral Centroid (mean and variance)
    \item Spectral Rolloff
    \item Spectral Bandwidth
\end{itemize}

\textbf{Cepstral Features:}
\begin{itemize}
    \item MFCCs (especially coefficients 1-5)
    \item Delta and Delta-Delta MFCCs (FMA)
\end{itemize}

\textbf{Temporal Features:}
\begin{itemize}
    \item Zero-Crossing Rate
    \item RMS Energy
    \item Tempo
\end{itemize}

\textbf{Spotify-Specific Features:}
\begin{itemize}
    \item Danceability
    \item Energy
    \item Valence
    \item Acousticness
\end{itemize}

\subsection{Statistical Insights}

\subsubsection{Distribution Patterns}

Analysis revealed that most audio features follow non-normal distributions:
\begin{itemize}
    \item GTZAN: 98.28\% non-normal features
    \item High skewness in spectral variance features
    \item Heavy-tailed distributions requiring robust statistics
\end{itemize}

\subsubsection{Outlier Impact}

Outlier removal significantly affected dataset sizes:
\begin{itemize}
    \item GTZAN: 60.2\% reduction (1,000 → 398)
    \item FMA: 67.38\% reduction (6,410 → 2,091)
    \item Spotify: 29.77\% outlier removal
\end{itemize}

This suggests that audio feature distributions contain substantial variability, and aggressive outlier removal may eliminate valid edge cases representing distinct sub-genres.

\section{Discussion}

\subsection{Performance Trends}

\subsubsection{Train-Test Split Impact}

Our experiments across four splits (50-50, 60-40, 70-30, 80-20) revealed interesting patterns:

\begin{itemize}
    \item \textbf{80-20 Split:} Generally produced highest accuracy and NMI scores
    \item \textbf{60-40 Split:} Provided best balance between training data and robust evaluation
    \item \textbf{Smaller Training Sets:} Led to less stable clustering assignments
    \item \textbf{Larger Training Sets:} Improved cluster quality metrics
\end{itemize}

\subsubsection{Dataset Characteristics}

\textbf{GTZAN Success Factors:}
\begin{itemize}
    \item Perfect class balance (100 samples per genre)
    \item Controlled recording conditions
    \item Moderate feature dimensionality (58 features)
    \item Clear genre distinctions
\end{itemize}

\textbf{FMA Challenges:}
\begin{itemize}
    \item Large scale (6,410 tracks) increases diversity
    \item 8 genres with potential overlap
    \item High dimensionality (155 features) may cause curse of dimensionality
    \item Real-world music with varying recording quality
\end{itemize}

\textbf{MSD Limitations:}
\begin{itemize}
    \item Small sample size (100 tracks) insufficient for robust clustering
    \item High feature dimensionality (134 features) relative to sample count
    \item Pre-computed features may not capture all genre characteristics
\end{itemize}

\textbf{Spotify Strengths:}
\begin{itemize}
    \item Massive scale (116,724 tracks) provides statistical power
    \item Well-engineered features from Spotify's API
    \item Lower dimensionality (13 features) reduces overfitting risk
    \item Professional audio quality
\end{itemize}

\subsection{Algorithm Characteristics}

\subsubsection{K-Means}
\textbf{Strengths:}
\begin{itemize}
    \item Consistently strong performance across datasets
    \item Fast execution time
    \item Interpretable centroids
    \item Scales well to large datasets
\end{itemize}

\textbf{Weaknesses:}
\begin{itemize}
    \item Assumes spherical clusters
    \item Sensitive to initialization (mitigated by k-means++)
    \item Requires predefined k
\end{itemize}

\subsubsection{Spectral Clustering}
\textbf{Strengths:}
\begin{itemize}
    \item Best performer on FMA dataset
    \item Captures non-linear patterns
    \item Flexible cluster shapes
\end{itemize}

\textbf{Weaknesses:}
\begin{itemize}
    \item Computationally expensive
    \item Memory-intensive for large datasets
    \item Sensitive to affinity parameter
\end{itemize}

\subsubsection{GMM}
\textbf{Strengths:}
\begin{itemize}
    \item Best on GTZAN (45\% accuracy)
    \item Probabilistic cluster assignments
    \item Models uncertainty
    \item Flexible covariance structures
\end{itemize}

\textbf{Weaknesses:}
\begin{itemize}
    \item Prone to local optima
    \item Requires careful initialization
    \item Computational complexity increases with dimensions
\end{itemize}

\subsubsection{MiniBatch K-Means}
\textbf{Strengths:}
\begin{itemize}
    \item Excellent scalability
    \item Reduced memory footprint
    \item Nearly matches K-Means accuracy
\end{itemize}

\textbf{Weaknesses:}
\begin{itemize}
    \item Slightly lower accuracy than standard K-Means
    \item Additional hyperparameter (batch size)
\end{itemize}

\subsubsection{DBSCAN}
\textbf{Strengths:}
\begin{itemize}
    \item Discovers arbitrary-shaped clusters
    \item Automatic noise detection
    \item No need to specify k
\end{itemize}

\textbf{Weaknesses:}
\begin{itemize}
    \item Poor performance on all datasets
    \item Extremely sensitive to eps parameter
    \item Struggles with varying densities in high dimensions
    \item Often classified all points as noise or single cluster
\end{itemize}

\subsection{Practical Implications}

\subsubsection{For Music Streaming Services}
\begin{itemize}
    \item K-Means provides fast, scalable genre discovery for large catalogs
    \item Spectral Clustering can identify nuanced sub-genres
    \item GMM enables soft clustering for tracks spanning multiple genres
    \item Feature engineering (Spotify's approach) crucial for performance
\end{itemize}

\subsubsection{For Music Recommendation Systems}
\begin{itemize}
    \item Unsupervised clustering can bootstrap new recommendation engines
    \item Cluster assignments provide similarity metrics for collaborative filtering
    \item Probabilistic assignments (GMM) model user preference uncertainty
\end{itemize}

\subsubsection{For Music Archive Organization}
\begin{itemize}
    \item Automated genre tagging reduces manual curation effort
    \item Multiple clustering algorithms can provide consensus labels
    \item Outlier detection identifies mislabeled or unique tracks
\end{itemize}

\subsection{Limitations}

\subsubsection{Methodological Limitations}
\begin{itemize}
    \item Clustering evaluation depends on ground-truth genre labels, which may be subjective
    \item Fixed k=10 may not reflect true genre structure in all datasets
    \item Outlier removal may eliminate valid edge cases
    \item Feature extraction settings may bias results
\end{itemize}

\subsubsection{Dataset Limitations}
\begin{itemize}
    \item GTZAN: Limited diversity, only 30-second clips
    \item FMA: Aggressive outlier removal (67\%) reduces usable data
    \item MSD: Small sample size limits statistical significance
    \item Spotify: Lacks ground-truth genre labels for supervised evaluation
\end{itemize}

\subsubsection{Computational Limitations}
\begin{itemize}
    \item Spectral Clustering infeasible for very large datasets
    \item Grid search for optimal hyperparameters computationally prohibitive
    \item Limited exploration of feature selection methods
\end{itemize}

\section{Conclusion}

This comprehensive study evaluated unsupervised music genre discovery across four diverse datasets using five clustering algorithms and multiple train-test configurations. Our key findings include:

\subsection{Primary Findings}

\begin{enumerate}
    \item \textbf{K-Means Dominance:} K-Means consistently delivered strong performance across datasets, achieving up to 45\% accuracy on GTZAN with GMM.

    \item \textbf{Dataset Characteristics Matter:} GTZAN's balanced structure yielded the best results (NMI: 0.4648), while FMA's scale and diversity presented challenges.

    \item \textbf{Spectral Clustering for Complexity:} Spectral Clustering excelled on complex datasets (FMA) where non-linear patterns exist.

    \item \textbf{Feature Engineering Critical:} Spotify's well-engineered features enabled strong performance despite massive scale.

    \item \textbf{DBSCAN Challenges:} DBSCAN struggled across all datasets, highlighting difficulties with high-dimensional audio data.

    \item \textbf{Train-Test Split Impact:} Larger training sets (70-30, 80-20) generally produced better clustering quality.
\end{enumerate}

\subsection{Contributions}

This research provides:
\begin{itemize}
    \item Comprehensive multi-dataset evaluation (12,234 tracks)
    \item Robust statistical analysis with trimmed statistics and outlier detection
    \item Multiple algorithm comparison under consistent conditions
    \item Practical insights for music recommendation systems
    \item Open-source implementation for reproducibility
\end{itemize}

\subsection{Future Work}

Promising directions for future research include:

\subsubsection{Advanced Feature Learning}
\begin{itemize}
    \item Deep learning-based feature extraction (e.g., VGGish, OpenL3)
    \item Learned embeddings from audio waveforms
    \item Multi-modal features (audio + lyrics + metadata)
\end{itemize}

\subsubsection{Advanced Clustering Methods}
\begin{itemize}
    \item Deep clustering (Deep Embedded Clustering)
    \item Hierarchical clustering to capture genre taxonomy
    \item Ensemble clustering combining multiple algorithms
\end{itemize}

\subsubsection{Optimal k Selection}
\begin{itemize}
    \item Elbow method and silhouette analysis for k determination
    \item Hierarchical approaches to discover natural genre count
    \item Dynamic clustering adapting to dataset characteristics
\end{itemize}

\subsubsection{Transfer Learning}
\begin{itemize}
    \item Pre-training on one dataset, fine-tuning on another
    \item Cross-dataset genre discovery
    \item Domain adaptation techniques
\end{itemize}

\subsubsection{Temporal Analysis}
\begin{itemize}
    \item Genre evolution over time (using year metadata)
    \item Trend detection in music characteristics
    \item Emerging genre identification
\end{itemize}

\subsubsection{Scalability Improvements}
\begin{itemize}
    \item Distributed clustering for million-song scale
    \item Online learning for streaming data
    \item Approximate methods for real-time applications
\end{itemize}

\subsection{Final Remarks}

This research demonstrates that unsupervised learning provides a viable approach for music genre discovery, with K-Means and Spectral Clustering emerging as practical choices for different scenarios. While supervised methods may achieve higher accuracy, unsupervised approaches offer scalability, flexibility, and the ability to discover emerging patterns without manual labeling. The comprehensive multi-dataset evaluation provides empirical evidence and practical guidelines for implementing music genre discovery systems in real-world applications.

\section{Acknowledgments}

The author acknowledges the creators of the GTZAN, FMA, Million Song, and Spotify datasets for making these resources publicly available. Special thanks to the scikit-learn and librosa communities for excellent open-source tools that made this research possible.

\begin{thebibliography}{00}

\bibitem{tzanetakis2002}
G. Tzanetakis and P. Cook, ``Musical genre classification of audio signals,'' \textit{IEEE Transactions on Speech and Audio Processing}, vol. 10, no. 5, pp. 293-302, 2002.

\bibitem{li2003}
T. Li, M. Ogihara, and Q. Li, ``A comparative study on content-based music genre classification,'' in \textit{Proc. 26th Annual International ACM SIGIR Conference}, 2003, pp. 282-289.

\bibitem{mandel2005}
M. I. Mandel and D. P. W. Ellis, ``Song-level features and support vector machines for music classification,'' in \textit{Proc. ISMIR}, 2005, pp. 594-599.

\bibitem{hoffman2009}
M. Hoffman, D. Blei, and P. Cook, ``Bayesian nonparametric matrix factorization for recorded music,'' in \textit{Proc. ICML}, 2009, pp. 439-446.

\bibitem{mcfee2012}
B. McFee and G. R. G. Lanckriet, ``Heterogeneous embedding for subjective artist similarity,'' in \textit{Proc. ISMIR}, 2012, pp. 291-296.

\bibitem{oord2013}
A. van den Oord, S. Dieleman, and B. Schrauwen, ``Deep content-based music recommendation,'' in \textit{Proc. NIPS}, 2013, pp. 2643-2651.

\bibitem{defferrard2016}
M. Defferrard, K. Benzi, P. Vandergheynst, and X. Bresson, ``FMA: A dataset for music analysis,'' in \textit{Proc. ISMIR}, 2017, pp. 316-323.

\bibitem{bertin2011}
T. Bertin-Mahieux, D. P. W. Ellis, B. Whitman, and P. Lamere, ``The Million Song Dataset,'' in \textit{Proc. ISMIR}, 2011, pp. 591-596.

\bibitem{pedregosa2011}
F. Pedregosa et al., ``Scikit-learn: Machine learning in Python,'' \textit{Journal of Machine Learning Research}, vol. 12, pp. 2825-2830, 2011.

\bibitem{mcfee2015}
B. McFee et al., ``librosa: Audio and music signal analysis in Python,'' in \textit{Proc. Python in Science Conference}, 2015, pp. 18-25.

\end{thebibliography}

\appendix

\section{Dataset Details}

\subsection{GTZAN Genre Distribution}
\begin{itemize}
    \item Blues: 100 tracks
    \item Classical: 100 tracks
    \item Country: 100 tracks
    \item Disco: 100 tracks
    \item Hip-Hop: 100 tracks
    \item Jazz: 100 tracks
    \item Metal: 100 tracks
    \item Pop: 100 tracks
    \item Reggae: 100 tracks
    \item Rock: 100 tracks
\end{itemize}

\subsection{FMA Genre Distribution (Top 8)}
\begin{itemize}
    \item Electronic
    \item Experimental
    \item Folk
    \item Hip-Hop
    \item Instrumental
    \item International
    \item Pop
    \item Rock
\end{itemize}

\subsection{Feature Extraction Parameters}

\textbf{GTZAN and FMA:}
\begin{itemize}
    \item Sampling Rate: 22,050 Hz
    \item MFCC Coefficients: 20
    \item FFT Window: 2048 samples
    \item Hop Length: 512 samples
    \item Mel Bands: 128
\end{itemize}

\textbf{Spotify Features:}
\begin{itemize}
    \item Acousticness: [0, 1]
    \item Danceability: [0, 1]
    \item Energy: [0, 1]
    \item Instrumentalness: [0, 1]
    \item Liveness: [0, 1]
    \item Loudness: [-60, 0] dB
    \item Speechiness: [0, 1]
    \item Tempo: [0, 250] BPM
    \item Valence: [0, 1]
    \item Duration: milliseconds
    \item Key: [0, 11]
    \item Mode: {0, 1}
    \item Time Signature: [3, 7]
\end{itemize}

\section{Computational Environment}

\textbf{Hardware:}
\begin{itemize}
    \item Processor: [Your processor details]
    \item RAM: [Your RAM details]
    \item Storage: SSD
\end{itemize}

\textbf{Software:}
\begin{itemize}
    \item Python: 3.8+
    \item NumPy: 1.21+
    \item Pandas: 1.3+
    \item Scikit-learn: 1.0+
    \item Librosa: 0.9+
    \item Matplotlib: 3.4+
    \item Seaborn: 0.11+
\end{itemize}

\section{Reproducibility}

All code and processed datasets are available at:
\begin{itemize}
    \item GitHub Repository: [Your repository URL]
    \item Dataset Links: See individual dataset sections
    \item Random Seed: 42 (for all experiments)
\end{itemize}

\section{Author Biography}

\textbf{Anirudh Sharma} is a student in the Department of Computer Science and Engineering, specializing in machine learning and music information retrieval. This work was completed as part of the Machine Learning course requirement.

\end{document}
