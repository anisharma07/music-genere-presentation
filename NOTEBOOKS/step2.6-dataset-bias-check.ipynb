{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753b1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import kruskal, f_oneway\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca223001",
   "metadata": {},
   "source": [
    "## 1. Load All Cleaned Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d07705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded FMA Small: 7,996 tracks, 75 features\n",
      "‚úì Loaded FMA Medium: 16,986 tracks, 75 features\n",
      "‚úì Loaded GTZAN: 999 tracks, 73 features\n",
      "‚úì Loaded Indian Music: 500 tracks, 74 features\n",
      "‚úì Loaded Ludwig: 11,293 tracks, 74 features\n",
      "\n",
      "üìä Combined dataset: 37,774 tracks, 76 total columns\n",
      "\n",
      "üìã Dataset Distribution:\n",
      "dataset\n",
      "FMA Medium      16986\n",
      "FMA Small        7996\n",
      "GTZAN             999\n",
      "Indian Music      500\n",
      "Ludwig          11293\n",
      "Name: count, dtype: int64\n",
      "‚úì Loaded Ludwig: 11,293 tracks, 74 features\n",
      "\n",
      "üìä Combined dataset: 37,774 tracks, 76 total columns\n",
      "\n",
      "üìã Dataset Distribution:\n",
      "dataset\n",
      "FMA Medium      16986\n",
      "FMA Small        7996\n",
      "GTZAN             999\n",
      "Indian Music      500\n",
      "Ludwig          11293\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "import os\n",
    "base_path = '/home/anirudh-sharma/Desktop/music-genere-presentation'\n",
    "datasets = {\n",
    "    'FMA Small': os.path.join(base_path, 'data/feature-extraction-cleaned/fma_small_features_labeled.csv'),\n",
    "    'FMA Medium': os.path.join(base_path, 'data/feature-extraction-cleaned/fma_medium_features_labeled.csv'),\n",
    "    'GTZAN': os.path.join(base_path, 'data/feature-extraction-cleaned/gtzan_features.csv'),\n",
    "    'Indian Music': os.path.join(base_path, 'data/feature-extraction-cleaned/indian_features.csv'),\n",
    "    'Ludwig': os.path.join(base_path, 'data/feature-extraction-cleaned/ludwig_features.csv')\n",
    "}\n",
    "\n",
    "# Load all datasets with dataset identifier\n",
    "dfs = []\n",
    "for name, path in datasets.items():\n",
    "    df = pd.read_csv(path)\n",
    "    df['dataset'] = name  # Add dataset identifier\n",
    "    dfs.append(df)\n",
    "    print(f\"‚úì Loaded {name}: {df.shape[0]:,} tracks, {df.shape[1]-1} features\")\n",
    "\n",
    "# Combine all datasets\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\nüìä Combined dataset: {combined_df.shape[0]:,} tracks, {combined_df.shape[1]} total columns\")\n",
    "print(f\"\\nüìã Dataset Distribution:\")\n",
    "print(combined_df['dataset'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bed961",
   "metadata": {},
   "source": [
    "## 2. Create Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00a4f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Results will be saved to: /home/anirudh-sharma/Desktop/music-genere-presentation/results/step1.6-dataset-bias-check\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = os.path.join(base_path, 'results/step1.6-dataset-bias-check')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"üìÅ Results will be saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837fd07",
   "metadata": {},
   "source": [
    "## 3. Key Features for Bias Detection\n",
    "\n",
    "We'll analyze features that are most likely to show recording/technical bias:\n",
    "- **rms_mean**: Loudness (recording level bias)\n",
    "- **spec_centroid_mean**: Brightness (equipment/encoding bias)\n",
    "- **tempo**: Rhythmic extraction bias\n",
    "- **zcr_mean**: Noisiness (bit depth/compression bias)\n",
    "- **mfcc1_mean**: Overall energy (normalization bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2f058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analyzing bias in the following features:\n",
      "   1. rms_mean\n",
      "   2. spec_centroid_mean\n",
      "   3. spec_rolloff_mean\n",
      "   4. tempo\n",
      "   5. zcr_mean\n",
      "   6. mfcc1_mean\n"
     ]
    }
   ],
   "source": [
    "# Define key features for bias analysis\n",
    "bias_features = [\n",
    "    'rms_mean',           # Loudness\n",
    "    'spec_centroid_mean', # Brightness\n",
    "    'spec_rolloff_mean',  # High-frequency content\n",
    "    'tempo',              # Rhythmic extraction\n",
    "    'zcr_mean',           # Zero-crossing rate (noisiness)\n",
    "    'mfcc1_mean'          # Overall energy\n",
    "]\n",
    "\n",
    "print(\"üìä Analyzing bias in the following features:\")\n",
    "for i, feat in enumerate(bias_features, 1):\n",
    "    print(f\"   {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c243a88",
   "metadata": {},
   "source": [
    "## 4. Statistical Summary by Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb04643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üìà DESCRIPTIVE STATISTICS BY DATASET\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Feature: rms_mean\n",
      "====================================================================================================\n",
      "                Mean  Median     Std     Min     Max     Q25     Q75\n",
      "dataset                                                             \n",
      "FMA Medium    0.1831  0.1750  0.0959  0.0000  0.9115  0.1124  0.2429\n",
      "FMA Small     0.1802  0.1699  0.0970  0.0000  0.8724  0.1074  0.2405\n",
      "GTZAN         0.1309  0.1222  0.0657  0.0053  0.3977  0.0866  0.1756\n",
      "Indian Music  0.1564  0.1534  0.0689  0.0228  0.3888  0.0966  0.2142\n",
      "Ludwig        0.1962  0.2013  0.0885  0.0000  0.5673  0.1272  0.2649\n",
      "\n",
      "====================================================================================================\n",
      "Feature: spec_centroid_mean\n",
      "====================================================================================================\n",
      "                   Mean     Median       Std       Min        Max        Q25  \\\n",
      "dataset                                                                        \n",
      "FMA Medium    2005.6462  2012.2467  703.0080   33.7095  7961.7338  1526.5577   \n",
      "FMA Small     1900.5601  1885.4190  710.2004  194.1829  6765.7466  1392.5559   \n",
      "GTZAN         2202.5984  2215.2672  716.1103  570.3499  4435.7321  1626.5270   \n",
      "Indian Music  2059.1919  2019.0902  455.7547  942.4791  3765.8591  1755.9243   \n",
      "Ludwig        2233.8245  2317.1112  629.5470   63.2247  4612.3375  1806.7755   \n",
      "\n",
      "                    Q75  \n",
      "dataset                  \n",
      "FMA Medium    2453.6621  \n",
      "FMA Small     2368.8656  \n",
      "GTZAN         2691.6952  \n",
      "Indian Music  2330.1660  \n",
      "Ludwig        2688.6002  \n",
      "\n",
      "====================================================================================================\n",
      "Feature: spec_rolloff_mean\n",
      "====================================================================================================\n",
      "                   Mean     Median        Std        Min         Max  \\\n",
      "dataset                                                                \n",
      "FMA Medium    4132.6207  4200.7956  1547.8912    20.9253  10072.9272   \n",
      "FMA Small     3921.1648  3979.0224  1569.2322   243.9430   9520.5447   \n",
      "GTZAN         4573.2893  4663.0126  1575.0936   749.7402   8677.7310   \n",
      "Indian Music  4394.5692  4344.8043  1072.6990  1681.3908   7950.0630   \n",
      "Ludwig        4652.5191  4883.5455  1395.4599   140.1325   9097.4450   \n",
      "\n",
      "                    Q25        Q75  \n",
      "dataset                             \n",
      "FMA Medium    3053.9664  5205.1163  \n",
      "FMA Small     2786.6859  5003.6307  \n",
      "GTZAN         3380.2091  5534.1165  \n",
      "Indian Music  3693.0793  5066.0833  \n",
      "Ludwig        3740.8524  5653.3741  \n",
      "\n",
      "====================================================================================================\n",
      "Feature: tempo\n",
      "====================================================================================================\n",
      "                  Mean    Median      Std      Min       Max      Q25  \\\n",
      "dataset                                                                 \n",
      "FMA Medium    120.6677  117.4538  28.9876   0.0000  287.1094  99.3840   \n",
      "FMA Small     119.0856  117.4538  29.0491   0.0000  258.3984  98.4638   \n",
      "GTZAN         119.2932  117.4538  28.0870  58.7269  234.9077  99.3840   \n",
      "Indian Music  121.6382  117.4538  28.9072  61.5234  215.3320  99.3840   \n",
      "Ludwig        119.2068  117.4538  27.5318  11.8531  287.1094  99.3840   \n",
      "\n",
      "                   Q75  \n",
      "dataset                 \n",
      "FMA Medium    135.9992  \n",
      "FMA Small     135.9992  \n",
      "GTZAN         135.9992  \n",
      "Indian Music  143.5547  \n",
      "Ludwig        135.9992  \n",
      "\n",
      "====================================================================================================\n",
      "Feature: zcr_mean\n",
      "====================================================================================================\n",
      "                Mean  Median     Std     Min     Max     Q25     Q75\n",
      "dataset                                                             \n",
      "FMA Medium    0.0905  0.0849  0.0450  0.0002  0.7553  0.0593  0.1137\n",
      "FMA Small     0.0842  0.0768  0.0441  0.0002  0.6270  0.0538  0.1058\n",
      "GTZAN         0.1037  0.0996  0.0418  0.0217  0.2746  0.0704  0.1321\n",
      "Indian Music  0.0894  0.0833  0.0295  0.0374  0.2070  0.0685  0.1045\n",
      "Ludwig        0.1043  0.1025  0.0378  0.0024  0.2875  0.0756  0.1305\n",
      "\n",
      "====================================================================================================\n",
      "Feature: mfcc1_mean\n",
      "====================================================================================================\n",
      "                  Mean    Median       Std        Min       Max       Q25  \\\n",
      "dataset                                                                     \n",
      "FMA Medium   -118.3793  -99.5628  106.2058  -948.9164  160.0906 -178.3017   \n",
      "FMA Small    -134.4056 -118.5479  104.4237  -985.5833  175.7648 -192.7972   \n",
      "GTZAN        -144.4868 -120.1475  100.2982  -552.1586   42.0914 -200.9130   \n",
      "Indian Music -129.4990 -123.6716   60.8158  -351.3492   -0.1594 -172.6266   \n",
      "Ludwig        -83.5276  -62.3805   99.3456 -1128.0177  100.5250 -125.7122   \n",
      "\n",
      "                  Q75  \n",
      "dataset                \n",
      "FMA Medium   -41.4273  \n",
      "FMA Small    -60.1516  \n",
      "GTZAN        -73.8183  \n",
      "Indian Music -82.2213  \n",
      "Ludwig       -14.5706  \n",
      "\n",
      "====================================================================================================\n",
      "üìä SUMMARY TABLE\n",
      "====================================================================================================\n",
      "           Feature      Dataset      Mean       Std             Range\n",
      "          rms_mean   FMA Medium    0.1831    0.0959       0.00 - 0.91\n",
      "          rms_mean    FMA Small    0.1802    0.0970       0.00 - 0.87\n",
      "          rms_mean        GTZAN    0.1309    0.0657       0.01 - 0.40\n",
      "          rms_mean Indian Music    0.1564    0.0689       0.02 - 0.39\n",
      "          rms_mean       Ludwig    0.1962    0.0885       0.00 - 0.57\n",
      "spec_centroid_mean   FMA Medium 2005.6462  703.0080   33.71 - 7961.73\n",
      "spec_centroid_mean    FMA Small 1900.5601  710.2004  194.18 - 6765.75\n",
      "spec_centroid_mean        GTZAN 2202.5984  716.1103  570.35 - 4435.73\n",
      "spec_centroid_mean Indian Music 2059.1919  455.7547  942.48 - 3765.86\n",
      "spec_centroid_mean       Ludwig 2233.8245  629.5470   63.22 - 4612.34\n",
      " spec_rolloff_mean   FMA Medium 4132.6207 1547.8912  20.93 - 10072.93\n",
      " spec_rolloff_mean    FMA Small 3921.1648 1569.2322  243.94 - 9520.54\n",
      " spec_rolloff_mean        GTZAN 4573.2893 1575.0936  749.74 - 8677.73\n",
      " spec_rolloff_mean Indian Music 4394.5692 1072.6990 1681.39 - 7950.06\n",
      " spec_rolloff_mean       Ludwig 4652.5191 1395.4599  140.13 - 9097.44\n",
      "             tempo   FMA Medium  120.6677   28.9876     0.00 - 287.11\n",
      "             tempo    FMA Small  119.0856   29.0491     0.00 - 258.40\n",
      "             tempo        GTZAN  119.2932   28.0870    58.73 - 234.91\n",
      "             tempo Indian Music  121.6382   28.9072    61.52 - 215.33\n",
      "             tempo       Ludwig  119.2068   27.5318    11.85 - 287.11\n",
      "          zcr_mean   FMA Medium    0.0905    0.0450       0.00 - 0.76\n",
      "          zcr_mean    FMA Small    0.0842    0.0441       0.00 - 0.63\n",
      "          zcr_mean        GTZAN    0.1037    0.0418       0.02 - 0.27\n",
      "          zcr_mean Indian Music    0.0894    0.0295       0.04 - 0.21\n",
      "          zcr_mean       Ludwig    0.1043    0.0378       0.00 - 0.29\n",
      "        mfcc1_mean   FMA Medium -118.3793  106.2058  -948.92 - 160.09\n",
      "        mfcc1_mean    FMA Small -134.4056  104.4237  -985.58 - 175.76\n",
      "        mfcc1_mean        GTZAN -144.4868  100.2982   -552.16 - 42.09\n",
      "        mfcc1_mean Indian Music -129.4990   60.8158   -351.35 - -0.16\n",
      "        mfcc1_mean       Ludwig  -83.5276   99.3456 -1128.02 - 100.53\n"
     ]
    }
   ],
   "source": [
    "# Compute descriptive statistics grouped by dataset\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìà DESCRIPTIVE STATISTICS BY DATASET\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "summary_stats = []\n",
    "\n",
    "for feature in bias_features:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Group by dataset and compute statistics\n",
    "    stats_df = combined_df.groupby('dataset')[feature].agg([\n",
    "        ('Mean', 'mean'),\n",
    "        ('Median', 'median'),\n",
    "        ('Std', 'std'),\n",
    "        ('Min', 'min'),\n",
    "        ('Max', 'max'),\n",
    "        ('Q25', lambda x: x.quantile(0.25)),\n",
    "        ('Q75', lambda x: x.quantile(0.75))\n",
    "    ]).round(4)\n",
    "    \n",
    "    print(stats_df)\n",
    "    \n",
    "    # Store for summary table\n",
    "    for dataset in stats_df.index:\n",
    "        summary_stats.append({\n",
    "            'Feature': feature,\n",
    "            'Dataset': dataset,\n",
    "            'Mean': stats_df.loc[dataset, 'Mean'],\n",
    "            'Std': stats_df.loc[dataset, 'Std'],\n",
    "            'Range': f\"{stats_df.loc[dataset, 'Min']:.2f} - {stats_df.loc[dataset, 'Max']:.2f}\"\n",
    "        })\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä SUMMARY TABLE\")\n",
    "print(\"=\"*100)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc980bc2",
   "metadata": {},
   "source": [
    "## 5. Box Plot Comparison Across Datasets\n",
    "\n",
    "Visual comparison of feature distributions to identify systematic differences between datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14412302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_comparison_boxplot(df, feature, output_path):\n",
    "    \"\"\"\n",
    "    Create box plot comparing feature distributions across datasets.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Create box plot\n",
    "    datasets_order = ['GTZAN', 'FMA Small', 'FMA Medium', 'Indian Music', 'Ludwig']\n",
    "    box_data = [df[df['dataset'] == ds][feature].dropna() for ds in datasets_order if ds in df['dataset'].unique()]\n",
    "    labels = [ds for ds in datasets_order if ds in df['dataset'].unique()]\n",
    "    \n",
    "    bp = ax.boxplot(box_data, labels=labels, patch_artist=True,\n",
    "                    notch=True, showmeans=True,\n",
    "                    boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                    medianprops=dict(color='red', linewidth=2),\n",
    "                    meanprops=dict(marker='D', markerfacecolor='green', markersize=8),\n",
    "                    whiskerprops=dict(linewidth=1.5),\n",
    "                    capprops=dict(linewidth=1.5))\n",
    "    \n",
    "    # Add color coding\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "    for patch, color in zip(bp['boxes'], colors[:len(labels)]):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_title(f'Dataset Comparison: {feature}\\nBox Plot Analysis', \n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Dataset', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(f'{feature} Value', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='lightblue', alpha=0.5, label='IQR (Q1-Q3)'),\n",
    "        plt.Line2D([0], [0], color='red', linewidth=2, label='Median'),\n",
    "        plt.Line2D([0], [0], marker='D', color='w', markerfacecolor='green', \n",
    "                   markersize=8, label='Mean')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "    \n",
    "    plt.xticks(rotation=15, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì Saved: {os.path.basename(output_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate box plots for all bias features\n",
    "print(\"\\nüìä Generating Dataset Comparison Box Plots...\\n\")\n",
    "\n",
    "for feature in bias_features:\n",
    "    output_path = os.path.join(output_dir, f'boxplot_comparison_{feature}.png')\n",
    "    plot_dataset_comparison_boxplot(combined_df, feature, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec5dd5",
   "metadata": {},
   "source": [
    "## 6. Statistical Significance Testing\n",
    "\n",
    "### Kruskal-Wallis H-Test\n",
    "Non-parametric test to determine if datasets have significantly different distributions.\n",
    "\n",
    "**Null Hypothesis (H‚ÇÄ):** All datasets have the same distribution for the feature.\n",
    "\n",
    "**Interpretation:**\n",
    "- p < 0.001: Strong evidence of bias (datasets are significantly different)\n",
    "- p < 0.05: Moderate evidence of bias\n",
    "- p ‚â• 0.05: No significant bias detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fab7723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üî¨ STATISTICAL SIGNIFICANCE TESTING: Kruskal-Wallis H-Test\n",
      "====================================================================================================\n",
      "\n",
      "üî¥ rms_mean:\n",
      "   H-statistic: 748.8197\n",
      "   P-value: 9.3404e-161\n",
      "   Result: STRONG BIAS\n",
      "\n",
      "üî¥ spec_centroid_mean:\n",
      "   H-statistic: 1522.1591\n",
      "   P-value: 0.0000e+00\n",
      "   Result: STRONG BIAS\n",
      "\n",
      "üî¥ spec_rolloff_mean:\n",
      "   H-statistic: 1433.4361\n",
      "   P-value: 3.8839e-309\n",
      "   Result: STRONG BIAS\n",
      "\n",
      "üî¥ tempo:\n",
      "   H-statistic: 21.8289\n",
      "   P-value: 2.1677e-04\n",
      "   Result: STRONG BIAS\n",
      "\n",
      "üî¥ zcr_mean:\n",
      "   H-statistic: 1829.5166\n",
      "   P-value: 0.0000e+00\n",
      "   Result: STRONG BIAS\n",
      "\n",
      "üî¥ mfcc1_mean:\n",
      "   H-statistic: 1863.4316\n",
      "   P-value: 0.0000e+00\n",
      "   Result: STRONG BIAS\n",
      "\n",
      "====================================================================================================\n",
      "üìä BIAS TEST SUMMARY\n",
      "====================================================================================================\n",
      "           Feature  H-Statistic       P-Value Significance\n",
      "          rms_mean   748.819749 9.340352e-161  STRONG BIAS\n",
      "spec_centroid_mean  1522.159057  0.000000e+00  STRONG BIAS\n",
      " spec_rolloff_mean  1433.436074 3.883876e-309  STRONG BIAS\n",
      "             tempo    21.828861  2.167686e-04  STRONG BIAS\n",
      "          zcr_mean  1829.516633  0.000000e+00  STRONG BIAS\n",
      "        mfcc1_mean  1863.431616  0.000000e+00  STRONG BIAS\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üî¨ STATISTICAL SIGNIFICANCE TESTING: Kruskal-Wallis H-Test\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "bias_test_results = []\n",
    "\n",
    "for feature in bias_features:\n",
    "    # Prepare data groups\n",
    "    groups = [combined_df[combined_df['dataset'] == ds][feature].dropna() \n",
    "              for ds in combined_df['dataset'].unique()]\n",
    "    \n",
    "    # Perform Kruskal-Wallis test\n",
    "    h_stat, p_value = kruskal(*groups)\n",
    "    \n",
    "    # Interpret results\n",
    "    if p_value < 0.001:\n",
    "        significance = \"STRONG BIAS\"\n",
    "        color = \"üî¥\"\n",
    "    elif p_value < 0.05:\n",
    "        significance = \"MODERATE BIAS\"\n",
    "        color = \"üü°\"\n",
    "    else:\n",
    "        significance = \"NO BIAS\"\n",
    "        color = \"üü¢\"\n",
    "    \n",
    "    bias_test_results.append({\n",
    "        'Feature': feature,\n",
    "        'H-Statistic': h_stat,\n",
    "        'P-Value': p_value,\n",
    "        'Significance': significance\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{color} {feature}:\")\n",
    "    print(f\"   H-statistic: {h_stat:.4f}\")\n",
    "    print(f\"   P-value: {p_value:.4e}\")\n",
    "    print(f\"   Result: {significance}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "bias_results_df = pd.DataFrame(bias_test_results)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä BIAS TEST SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(bias_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3cbfc6",
   "metadata": {},
   "source": [
    "## 7. Effect Size Analysis (Cohen's d)\n",
    "\n",
    "Quantify the magnitude of differences between datasets using Cohen's d effect size.\n",
    "\n",
    "**Interpretation:**\n",
    "- |d| < 0.2: Negligible difference\n",
    "- 0.2 ‚â§ |d| < 0.5: Small difference\n",
    "- 0.5 ‚â§ |d| < 0.8: Medium difference\n",
    "- |d| ‚â• 0.8: Large difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c383c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üìè EFFECT SIZE ANALYSIS: Cohen's d (Pairwise Comparisons)\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Feature: rms_mean\n",
      "====================================================================================================\n",
      "üü¢ FMA Small vs FMA Medium: d = -0.0300 (Negligible)\n",
      "üü† FMA Small vs GTZAN: d = 0.5250 (Medium)\n",
      "üü° FMA Small vs Indian Music: d = 0.2498 (Small)\n",
      "üü¢ FMA Small vs Ludwig: d = -0.1737 (Negligible)\n",
      "üü† FMA Medium vs GTZAN: d = 0.5533 (Medium)\n",
      "üü° FMA Medium vs Indian Music: d = 0.2811 (Small)\n",
      "üü¢ FMA Medium vs Ludwig: d = -0.1410 (Negligible)\n",
      "üü° GTZAN vs Indian Music: d = -0.3818 (Small)\n",
      "üü† GTZAN vs Ludwig: d = -0.7523 (Medium)\n",
      "üü° Indian Music vs Ludwig: d = -0.4542 (Small)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: spec_centroid_mean\n",
      "====================================================================================================\n",
      "üü¢ FMA Small vs FMA Medium: d = -0.1490 (Negligible)\n",
      "üü° FMA Small vs GTZAN: d = -0.4249 (Small)\n",
      "üü° FMA Small vs Indian Music: d = -0.2273 (Small)\n",
      "üü† FMA Small vs Ludwig: d = -0.5018 (Medium)\n",
      "üü° FMA Medium vs GTZAN: d = -0.2799 (Small)\n",
      "üü¢ FMA Medium vs Indian Music: d = -0.0768 (Negligible)\n",
      "üü° FMA Medium vs Ludwig: d = -0.3382 (Small)\n",
      "üü° GTZAN vs Indian Music: d = 0.2237 (Small)\n",
      "üü¢ GTZAN vs Ludwig: d = -0.0490 (Negligible)\n",
      "üü° Indian Music vs Ludwig: d = -0.2802 (Small)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: spec_rolloff_mean\n",
      "====================================================================================================\n",
      "üü¢ FMA Small vs FMA Medium: d = -0.1360 (Negligible)\n",
      "üü° FMA Small vs GTZAN: d = -0.4154 (Small)\n",
      "üü° FMA Small vs Indian Music: d = -0.3065 (Small)\n",
      "üü° FMA Small vs Ludwig: d = -0.4975 (Small)\n",
      "üü° FMA Medium vs GTZAN: d = -0.2844 (Small)\n",
      "üü¢ FMA Medium vs Indian Music: d = -0.1705 (Negligible)\n",
      "üü° FMA Medium vs Ludwig: d = -0.3492 (Small)\n",
      "üü¢ GTZAN vs Indian Music: d = 0.1252 (Negligible)\n",
      "üü¢ GTZAN vs Ludwig: d = -0.0562 (Negligible)\n",
      "üü¢ Indian Music vs Ludwig: d = -0.1865 (Negligible)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: tempo\n",
      "====================================================================================================\n",
      "üü¢ FMA Small vs FMA Medium: d = -0.0545 (Negligible)\n",
      "üü¢ FMA Small vs GTZAN: d = -0.0072 (Negligible)\n",
      "üü¢ FMA Small vs Indian Music: d = -0.0879 (Negligible)\n",
      "üü¢ FMA Small vs Ludwig: d = -0.0043 (Negligible)\n",
      "üü¢ FMA Medium vs GTZAN: d = 0.0475 (Negligible)\n",
      "üü¢ FMA Medium vs Indian Music: d = -0.0335 (Negligible)\n",
      "üü¢ FMA Medium vs Ludwig: d = 0.0514 (Negligible)\n",
      "üü¢ GTZAN vs Indian Music: d = -0.0827 (Negligible)\n",
      "üü¢ GTZAN vs Ludwig: d = 0.0031 (Negligible)\n",
      "üü¢ Indian Music vs Ludwig: d = 0.0881 (Negligible)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: zcr_mean\n",
      "====================================================================================================\n",
      "üü¢ FMA Small vs FMA Medium: d = -0.1411 (Negligible)\n",
      "üü° FMA Small vs GTZAN: d = -0.4429 (Small)\n",
      "üü¢ FMA Small vs Indian Music: d = -0.1197 (Negligible)\n",
      "üü° FMA Small vs Ludwig: d = -0.4958 (Small)\n",
      "üü° FMA Medium vs GTZAN: d = -0.2929 (Small)\n",
      "üü¢ FMA Medium vs Indian Music: d = 0.0249 (Negligible)\n",
      "üü° FMA Medium vs Ludwig: d = -0.3266 (Small)\n",
      "üü° GTZAN vs Indian Music: d = 0.3730 (Small)\n",
      "üü¢ GTZAN vs Ludwig: d = -0.0178 (Negligible)\n",
      "üü° Indian Music vs Ludwig: d = -0.3975 (Small)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: mfcc1_mean\n",
      "====================================================================================================\n",
      "üü¢ FMA Small vs FMA Medium: d = -0.1517 (Negligible)\n",
      "üü¢ FMA Small vs GTZAN: d = 0.0970 (Negligible)\n",
      "üü¢ FMA Small vs Indian Music: d = -0.0479 (Negligible)\n",
      "üü† FMA Small vs Ludwig: d = -0.5014 (Medium)\n",
      "üü° FMA Medium vs GTZAN: d = 0.2466 (Small)\n",
      "üü¢ FMA Medium vs Indian Music: d = 0.1057 (Negligible)\n",
      "üü° FMA Medium vs Ludwig: d = -0.3367 (Small)\n",
      "üü¢ GTZAN vs Indian Music: d = -0.1682 (Negligible)\n",
      "üü† GTZAN vs Ludwig: d = -0.6131 (Medium)\n",
      "üü° Indian Music vs Ludwig: d = -0.4690 (Small)\n",
      "\n",
      "====================================================================================================\n",
      "üìä TOP 20 LARGEST EFFECT SIZES (Strongest Dataset Biases)\n",
      "====================================================================================================\n",
      "           Feature    Dataset_1    Dataset_2   Cohen_d  Abs_Cohen_d Effect_Size\n",
      "          rms_mean        GTZAN       Ludwig -0.752324     0.752324      Medium\n",
      "        mfcc1_mean        GTZAN       Ludwig -0.613128     0.613128      Medium\n",
      "          rms_mean   FMA Medium        GTZAN  0.553298     0.553298      Medium\n",
      "          rms_mean    FMA Small        GTZAN  0.525007     0.525007      Medium\n",
      "spec_centroid_mean    FMA Small       Ludwig -0.501776     0.501776      Medium\n",
      "        mfcc1_mean    FMA Small       Ludwig -0.501353     0.501353      Medium\n",
      " spec_rolloff_mean    FMA Small       Ludwig -0.497524     0.497524       Small\n",
      "          zcr_mean    FMA Small       Ludwig -0.495816     0.495816       Small\n",
      "        mfcc1_mean Indian Music       Ludwig -0.468988     0.468988       Small\n",
      "          rms_mean Indian Music       Ludwig -0.454215     0.454215       Small\n",
      "          zcr_mean    FMA Small        GTZAN -0.442898     0.442898       Small\n",
      "spec_centroid_mean    FMA Small        GTZAN -0.424892     0.424892       Small\n",
      " spec_rolloff_mean    FMA Small        GTZAN -0.415397     0.415397       Small\n",
      "          zcr_mean Indian Music       Ludwig -0.397466     0.397466       Small\n",
      "          rms_mean        GTZAN Indian Music -0.381751     0.381751       Small\n",
      "          zcr_mean        GTZAN Indian Music  0.372979     0.372979       Small\n",
      " spec_rolloff_mean   FMA Medium       Ludwig -0.349185     0.349185       Small\n",
      "spec_centroid_mean   FMA Medium       Ludwig -0.338226     0.338226       Small\n",
      "        mfcc1_mean   FMA Medium       Ludwig -0.336663     0.336663       Small\n",
      "          zcr_mean   FMA Medium       Ludwig -0.326574     0.326574       Small\n",
      "üü° FMA Small vs Ludwig: d = -0.4958 (Small)\n",
      "üü° FMA Medium vs GTZAN: d = -0.2929 (Small)\n",
      "üü¢ FMA Medium vs Indian Music: d = 0.0249 (Negligible)\n",
      "üü° FMA Medium vs Ludwig: d = -0.3266 (Small)\n",
      "üü° GTZAN vs Indian Music: d = 0.3730 (Small)\n",
      "üü¢ GTZAN vs Ludwig: d = -0.0178 (Negligible)\n",
      "üü° Indian Music vs Ludwig: d = -0.3975 (Small)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: mfcc1_mean\n",
      "====================================================================================================\n",
      "üü¢ FMA Small vs FMA Medium: d = -0.1517 (Negligible)\n",
      "üü¢ FMA Small vs GTZAN: d = 0.0970 (Negligible)\n",
      "üü¢ FMA Small vs Indian Music: d = -0.0479 (Negligible)\n",
      "üü† FMA Small vs Ludwig: d = -0.5014 (Medium)\n",
      "üü° FMA Medium vs GTZAN: d = 0.2466 (Small)\n",
      "üü¢ FMA Medium vs Indian Music: d = 0.1057 (Negligible)\n",
      "üü° FMA Medium vs Ludwig: d = -0.3367 (Small)\n",
      "üü¢ GTZAN vs Indian Music: d = -0.1682 (Negligible)\n",
      "üü† GTZAN vs Ludwig: d = -0.6131 (Medium)\n",
      "üü° Indian Music vs Ludwig: d = -0.4690 (Small)\n",
      "\n",
      "====================================================================================================\n",
      "üìä TOP 20 LARGEST EFFECT SIZES (Strongest Dataset Biases)\n",
      "====================================================================================================\n",
      "           Feature    Dataset_1    Dataset_2   Cohen_d  Abs_Cohen_d Effect_Size\n",
      "          rms_mean        GTZAN       Ludwig -0.752324     0.752324      Medium\n",
      "        mfcc1_mean        GTZAN       Ludwig -0.613128     0.613128      Medium\n",
      "          rms_mean   FMA Medium        GTZAN  0.553298     0.553298      Medium\n",
      "          rms_mean    FMA Small        GTZAN  0.525007     0.525007      Medium\n",
      "spec_centroid_mean    FMA Small       Ludwig -0.501776     0.501776      Medium\n",
      "        mfcc1_mean    FMA Small       Ludwig -0.501353     0.501353      Medium\n",
      " spec_rolloff_mean    FMA Small       Ludwig -0.497524     0.497524       Small\n",
      "          zcr_mean    FMA Small       Ludwig -0.495816     0.495816       Small\n",
      "        mfcc1_mean Indian Music       Ludwig -0.468988     0.468988       Small\n",
      "          rms_mean Indian Music       Ludwig -0.454215     0.454215       Small\n",
      "          zcr_mean    FMA Small        GTZAN -0.442898     0.442898       Small\n",
      "spec_centroid_mean    FMA Small        GTZAN -0.424892     0.424892       Small\n",
      " spec_rolloff_mean    FMA Small        GTZAN -0.415397     0.415397       Small\n",
      "          zcr_mean Indian Music       Ludwig -0.397466     0.397466       Small\n",
      "          rms_mean        GTZAN Indian Music -0.381751     0.381751       Small\n",
      "          zcr_mean        GTZAN Indian Music  0.372979     0.372979       Small\n",
      " spec_rolloff_mean   FMA Medium       Ludwig -0.349185     0.349185       Small\n",
      "spec_centroid_mean   FMA Medium       Ludwig -0.338226     0.338226       Small\n",
      "        mfcc1_mean   FMA Medium       Ludwig -0.336663     0.336663       Small\n",
      "          zcr_mean   FMA Medium       Ludwig -0.326574     0.326574       Small\n"
     ]
    }
   ],
   "source": [
    "def cohens_d(group1, group2):\n",
    "    \"\"\"\n",
    "    Calculate Cohen's d effect size between two groups.\n",
    "    \"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = group1.var(), group2.var()\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    return (group1.mean() - group2.mean()) / pooled_std\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìè EFFECT SIZE ANALYSIS: Cohen's d (Pairwise Comparisons)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "effect_size_results = []\n",
    "datasets_list = combined_df['dataset'].unique()\n",
    "\n",
    "for feature in bias_features:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Compare all pairs of datasets\n",
    "    for i, ds1 in enumerate(datasets_list):\n",
    "        for ds2 in datasets_list[i+1:]:\n",
    "            group1 = combined_df[combined_df['dataset'] == ds1][feature].dropna()\n",
    "            group2 = combined_df[combined_df['dataset'] == ds2][feature].dropna()\n",
    "            \n",
    "            d = cohens_d(group1, group2)\n",
    "            abs_d = abs(d)\n",
    "            \n",
    "            # Interpret effect size\n",
    "            if abs_d < 0.2:\n",
    "                interpretation = \"Negligible\"\n",
    "                emoji = \"üü¢\"\n",
    "            elif abs_d < 0.5:\n",
    "                interpretation = \"Small\"\n",
    "                emoji = \"üü°\"\n",
    "            elif abs_d < 0.8:\n",
    "                interpretation = \"Medium\"\n",
    "                emoji = \"üü†\"\n",
    "            else:\n",
    "                interpretation = \"Large\"\n",
    "                emoji = \"üî¥\"\n",
    "            \n",
    "            effect_size_results.append({\n",
    "                'Feature': feature,\n",
    "                'Dataset_1': ds1,\n",
    "                'Dataset_2': ds2,\n",
    "                'Cohen_d': d,\n",
    "                'Abs_Cohen_d': abs_d,\n",
    "                'Effect_Size': interpretation\n",
    "            })\n",
    "            \n",
    "            print(f\"{emoji} {ds1} vs {ds2}: d = {d:.4f} ({interpretation})\")\n",
    "\n",
    "# Create effect size DataFrame\n",
    "effect_size_df = pd.DataFrame(effect_size_results)\n",
    "effect_size_df = effect_size_df.sort_values('Abs_Cohen_d', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä TOP 20 LARGEST EFFECT SIZES (Strongest Dataset Biases)\")\n",
    "print(\"=\"*100)\n",
    "print(effect_size_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c78d60",
   "metadata": {},
   "source": [
    "## 8. Violin Plot Comparison\n",
    "\n",
    "Show distribution shapes and probability density for key features across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787af763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin_comparison(df, feature, output_path):\n",
    "    \"\"\"\n",
    "    Create violin plot showing distribution shapes across datasets.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Create violin plot\n",
    "    datasets_order = ['GTZAN', 'FMA Small', 'FMA Medium', 'Indian Music', 'Ludwig']\n",
    "    plot_df = df[df['dataset'].isin(datasets_order)]\n",
    "    \n",
    "    sns.violinplot(data=plot_df, x='dataset', y=feature, \n",
    "                   order=datasets_order, palette='Set2',\n",
    "                   inner='quartile', ax=ax)\n",
    "    \n",
    "    # Overlay strip plot for data points\n",
    "    sns.stripplot(data=plot_df, x='dataset', y=feature,\n",
    "                  order=datasets_order, color='black',\n",
    "                  alpha=0.1, size=2, ax=ax)\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_title(f'Distribution Shape Comparison: {feature}\\nViolin Plot with Quartiles',\n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Dataset', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(f'{feature} Value', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.xticks(rotation=15, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì Saved: {os.path.basename(output_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate violin plots for key features\n",
    "print(\"\\nüìä Generating Violin Plots for Distribution Shape Analysis...\\n\")\n",
    "\n",
    "key_features_violin = ['rms_mean', 'spec_centroid_mean', 'tempo']\n",
    "for feature in key_features_violin:\n",
    "    output_path = os.path.join(output_dir, f'violin_comparison_{feature}.png')\n",
    "    plot_violin_comparison(combined_df, feature, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059bede",
   "metadata": {},
   "source": [
    "## 9. 2D Feature Space Visualization\n",
    "\n",
    "Visualize dataset separation in 2D feature space to assess clustering by source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_feature_space(df, feature_x, feature_y, output_path):\n",
    "    \"\"\"\n",
    "    Create 2D scatter plot showing dataset separation.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Create scatter plot with different colors for each dataset\n",
    "    datasets = df['dataset'].unique()\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "    \n",
    "    for i, dataset in enumerate(datasets):\n",
    "        subset = df[df['dataset'] == dataset]\n",
    "        ax.scatter(subset[feature_x], subset[feature_y],\n",
    "                   c=colors[i], label=dataset, alpha=0.5, s=20, edgecolors='none')\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_title(f'2D Feature Space: Dataset Separation\\n{feature_x} vs {feature_y}',\n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel(feature_x, fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(feature_y, fontsize=14, fontweight='bold')\n",
    "    ax.legend(title='Dataset', fontsize=11, title_fontsize=12, loc='best')\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì Saved: {os.path.basename(output_path)}\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate 2D feature space plots\n",
    "print(\"\\nüìä Generating 2D Feature Space Visualizations...\\n\")\n",
    "\n",
    "feature_pairs = [\n",
    "    ('rms_mean', 'spec_centroid_mean'),\n",
    "    ('tempo', 'zcr_mean'),\n",
    "    ('spec_centroid_mean', 'spec_rolloff_mean')\n",
    "]\n",
    "\n",
    "for feat_x, feat_y in feature_pairs:\n",
    "    output_path = os.path.join(output_dir, f'2d_scatter_{feat_x}_vs_{feat_y}.png')\n",
    "    plot_2d_feature_space(combined_df, feat_x, feat_y, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae3ac8",
   "metadata": {},
   "source": [
    "## 10. Coefficient of Variation (CV) Analysis\n",
    "\n",
    "Measure relative variability within each dataset to assess consistency.\n",
    "\n",
    "**Formula:** CV = (œÉ / Œº) √ó 100%\n",
    "\n",
    "**Interpretation:**\n",
    "- CV < 20%: Low variability (homogeneous)\n",
    "- 20% ‚â§ CV < 50%: Moderate variability\n",
    "- CV ‚â• 50%: High variability (heterogeneous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d348e3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üìä COEFFICIENT OF VARIATION (CV) ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Feature: rms_mean\n",
      "====================================================================================================\n",
      "üî¥ FMA Small: CV = 53.83% (High)\n",
      "üî¥ FMA Medium: CV = 52.37% (High)\n",
      "üî¥ GTZAN: CV = 50.23% (High)\n",
      "üü° Indian Music: CV = 44.09% (Moderate)\n",
      "üü° Ludwig: CV = 45.12% (Moderate)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: spec_centroid_mean\n",
      "====================================================================================================\n",
      "üü° FMA Small: CV = 37.37% (Moderate)\n",
      "üü° FMA Medium: CV = 35.05% (Moderate)\n",
      "üü° GTZAN: CV = 32.51% (Moderate)\n",
      "üü° Indian Music: CV = 22.13% (Moderate)\n",
      "üü° Ludwig: CV = 28.18% (Moderate)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: spec_rolloff_mean\n",
      "====================================================================================================\n",
      "üü° FMA Small: CV = 40.02% (Moderate)\n",
      "üü° FMA Medium: CV = 37.46% (Moderate)\n",
      "üü° GTZAN: CV = 34.44% (Moderate)\n",
      "üü° Indian Music: CV = 24.41% (Moderate)\n",
      "üü° Ludwig: CV = 29.99% (Moderate)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: tempo\n",
      "====================================================================================================\n",
      "üü° FMA Small: CV = 24.39% (Moderate)\n",
      "üü° FMA Medium: CV = 24.02% (Moderate)\n",
      "üü° GTZAN: CV = 23.54% (Moderate)\n",
      "üü° Indian Music: CV = 23.76% (Moderate)\n",
      "üü° Ludwig: CV = 23.10% (Moderate)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: zcr_mean\n",
      "====================================================================================================\n",
      "üî¥ FMA Small: CV = 52.40% (High)\n",
      "üü° FMA Medium: CV = 49.68% (Moderate)\n",
      "üü° GTZAN: CV = 40.35% (Moderate)\n",
      "üü° Indian Music: CV = 33.03% (Moderate)\n",
      "üü° Ludwig: CV = 36.27% (Moderate)\n",
      "\n",
      "====================================================================================================\n",
      "Feature: mfcc1_mean\n",
      "====================================================================================================\n",
      "üü¢ FMA Small: CV = -77.69% (Low)\n",
      "üü¢ FMA Medium: CV = -89.72% (Low)\n",
      "üü¢ GTZAN: CV = -69.42% (Low)\n",
      "üü¢ Indian Music: CV = -46.96% (Low)\n",
      "üü¢ Ludwig: CV = -118.94% (Low)\n",
      "\n",
      "====================================================================================================\n",
      "üìä COEFFICIENT OF VARIATION SUMMARY\n",
      "====================================================================================================\n",
      "           Feature      Dataset        Mean         Std        CV_% Variability\n",
      "          rms_mean    FMA Small    0.180237    0.097020   53.829452        High\n",
      "          rms_mean   FMA Medium    0.183126    0.095896   52.366132        High\n",
      "          rms_mean        GTZAN    0.130853    0.065726   50.228639        High\n",
      "          rms_mean Indian Music    0.156359    0.068938   44.089203    Moderate\n",
      "          rms_mean       Ludwig    0.196240    0.088542   45.119326    Moderate\n",
      "spec_centroid_mean    FMA Small 1900.560114  710.200361   37.367950    Moderate\n",
      "spec_centroid_mean   FMA Medium 2005.646171  703.007989   35.051446    Moderate\n",
      "spec_centroid_mean        GTZAN 2202.598387  716.110283   32.512068    Moderate\n",
      "spec_centroid_mean Indian Music 2059.191945  455.754682   22.132695    Moderate\n",
      "spec_centroid_mean       Ludwig 2233.824532  629.547013   28.182474    Moderate\n",
      " spec_rolloff_mean    FMA Small 3921.164846 1569.232246   40.019543    Moderate\n",
      " spec_rolloff_mean   FMA Medium 4132.620732 1547.891232   37.455439    Moderate\n",
      " spec_rolloff_mean        GTZAN 4573.289295 1575.093587   34.441154    Moderate\n",
      " spec_rolloff_mean Indian Music 4394.569157 1072.699004   24.409651    Moderate\n",
      " spec_rolloff_mean       Ludwig 4652.519099 1395.459927   29.993642    Moderate\n",
      "             tempo    FMA Small  119.085594   29.049078   24.393445    Moderate\n",
      "             tempo   FMA Medium  120.667667   28.987643   24.022709    Moderate\n",
      "             tempo        GTZAN  119.293183   28.086954   23.544475    Moderate\n",
      "             tempo Indian Music  121.638213   28.907184   23.764887    Moderate\n",
      "             tempo       Ludwig  119.206758   27.531843   23.095874    Moderate\n",
      "          zcr_mean    FMA Small    0.084226    0.044131   52.395355        High\n",
      "          zcr_mean   FMA Medium    0.090535    0.044975   49.677128    Moderate\n",
      "          zcr_mean        GTZAN    0.103661    0.041825   40.347508    Moderate\n",
      "          zcr_mean Indian Music    0.089424    0.029535   33.028342    Moderate\n",
      "          zcr_mean       Ludwig    0.104340    0.037842   36.267717    Moderate\n",
      "        mfcc1_mean    FMA Small -134.405637  104.423740  -77.692976         Low\n",
      "        mfcc1_mean   FMA Medium -118.379297  106.205807  -89.716538         Low\n",
      "        mfcc1_mean        GTZAN -144.486845  100.298200  -69.416839         Low\n",
      "        mfcc1_mean Indian Music -129.498973   60.815790  -46.962373         Low\n",
      "        mfcc1_mean       Ludwig  -83.527648   99.345587 -118.937369         Low\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä COEFFICIENT OF VARIATION (CV) ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for feature in bias_features:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    for dataset in combined_df['dataset'].unique():\n",
    "        subset = combined_df[combined_df['dataset'] == dataset][feature].dropna()\n",
    "        mean_val = subset.mean()\n",
    "        std_val = subset.std()\n",
    "        cv = (std_val / mean_val) * 100 if mean_val != 0 else 0\n",
    "        \n",
    "        # Interpret CV\n",
    "        if cv < 20:\n",
    "            variability = \"Low\"\n",
    "            emoji = \"üü¢\"\n",
    "        elif cv < 50:\n",
    "            variability = \"Moderate\"\n",
    "            emoji = \"üü°\"\n",
    "        else:\n",
    "            variability = \"High\"\n",
    "            emoji = \"üî¥\"\n",
    "        \n",
    "        cv_results.append({\n",
    "            'Feature': feature,\n",
    "            'Dataset': dataset,\n",
    "            'Mean': mean_val,\n",
    "            'Std': std_val,\n",
    "            'CV_%': cv,\n",
    "            'Variability': variability\n",
    "        })\n",
    "        \n",
    "        print(f\"{emoji} {dataset}: CV = {cv:.2f}% ({variability})\")\n",
    "\n",
    "# Create CV DataFrame\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä COEFFICIENT OF VARIATION SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(cv_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b53f87",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e43165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved: bias_test_results.csv\n",
      "‚úì Saved: effect_size_analysis.csv\n",
      "‚úì Saved: coefficient_of_variation.csv\n",
      "‚úì Saved: descriptive_statistics_by_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save statistical test results\n",
    "bias_results_df.to_csv(os.path.join(output_dir, 'bias_test_results.csv'), index=False)\n",
    "print(\"‚úì Saved: bias_test_results.csv\")\n",
    "\n",
    "# Save effect size results\n",
    "effect_size_df.to_csv(os.path.join(output_dir, 'effect_size_analysis.csv'), index=False)\n",
    "print(\"‚úì Saved: effect_size_analysis.csv\")\n",
    "\n",
    "# Save CV results\n",
    "cv_df.to_csv(os.path.join(output_dir, 'coefficient_of_variation.csv'), index=False)\n",
    "print(\"‚úì Saved: coefficient_of_variation.csv\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_df.to_csv(os.path.join(output_dir, 'descriptive_statistics_by_dataset.csv'), index=False)\n",
    "print(\"‚úì Saved: descriptive_statistics_by_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0be0f3",
   "metadata": {},
   "source": [
    "## 12. Bias Assessment Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c58bf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üìã STEP 1.6: DATASET BIAS CHECK - FINAL SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "üîç BIAS DETECTION SUMMARY:\n",
      "   ‚Ä¢ Features with STRONG bias (p < 0.001): 6/6\n",
      "   ‚Ä¢ Features with MODERATE bias (p < 0.05): 0/6\n",
      "   ‚Ä¢ Features with NO bias (p ‚â• 0.05): 0/6\n",
      "\n",
      "‚ö†Ô∏è  BIASED FEATURES DETECTED:\n",
      "   ‚Ä¢ rms_mean\n",
      "   ‚Ä¢ spec_centroid_mean\n",
      "   ‚Ä¢ spec_rolloff_mean\n",
      "   ‚Ä¢ tempo\n",
      "   ‚Ä¢ zcr_mean\n",
      "   ‚Ä¢ mfcc1_mean\n",
      "\n",
      "üìè EFFECT SIZE SUMMARY:\n",
      "   ‚Ä¢ Pairwise comparisons with LARGE effect (|d| ‚â• 0.8): 0\n",
      "   ‚Ä¢ Pairwise comparisons with MEDIUM effect (0.5 ‚â§ |d| < 0.8): 6\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚ö†Ô∏è  STRONG DATASET BIAS DETECTED:\n",
      "   1. Consider dataset-specific normalization (Z-score per dataset)\n",
      "   2. Apply domain adaptation techniques before clustering\n",
      "   3. Evaluate clustering results with stratified validation by dataset\n",
      "   4. Report dataset as a potential confounding variable\n",
      "   5. Consider training separate models per dataset or using dataset as a feature\n",
      "\n",
      "üìä NEXT STEPS:\n",
      "   1. Apply appropriate normalization based on bias findings\n",
      "   2. Proceed to PCA dimensionality reduction (Step 3)\n",
      "   3. During clustering, verify that dataset != cluster\n",
      "   4. Use cross-tabulation to check cluster-dataset relationships\n",
      "\n",
      "====================================================================================================\n",
      "‚úÖ STEP 1.6 COMPLETE: Dataset Bias Assessment Finished\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìã STEP 1.6: DATASET BIAS CHECK - FINAL SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Count bias levels\n",
    "strong_bias_count = len(bias_results_df[bias_results_df['Significance'] == 'STRONG BIAS'])\n",
    "moderate_bias_count = len(bias_results_df[bias_results_df['Significance'] == 'MODERATE BIAS'])\n",
    "no_bias_count = len(bias_results_df[bias_results_df['Significance'] == 'NO BIAS'])\n",
    "\n",
    "print(f\"\\nüîç BIAS DETECTION SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Features with STRONG bias (p < 0.001): {strong_bias_count}/{len(bias_features)}\")\n",
    "print(f\"   ‚Ä¢ Features with MODERATE bias (p < 0.05): {moderate_bias_count}/{len(bias_features)}\")\n",
    "print(f\"   ‚Ä¢ Features with NO bias (p ‚â• 0.05): {no_bias_count}/{len(bias_features)}\")\n",
    "\n",
    "# Identify most biased features\n",
    "biased_features = bias_results_df[bias_results_df['P-Value'] < 0.05]['Feature'].tolist()\n",
    "if biased_features:\n",
    "    print(f\"\\n‚ö†Ô∏è  BIASED FEATURES DETECTED:\")\n",
    "    for feat in biased_features:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ NO SIGNIFICANT BIAS DETECTED\")\n",
    "\n",
    "# Count large effect sizes\n",
    "large_effects = len(effect_size_df[effect_size_df['Effect_Size'] == 'Large'])\n",
    "medium_effects = len(effect_size_df[effect_size_df['Effect_Size'] == 'Medium'])\n",
    "\n",
    "print(f\"\\nüìè EFFECT SIZE SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Pairwise comparisons with LARGE effect (|d| ‚â• 0.8): {large_effects}\")\n",
    "print(f\"   ‚Ä¢ Pairwise comparisons with MEDIUM effect (0.5 ‚â§ |d| < 0.8): {medium_effects}\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "\n",
    "if strong_bias_count > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  STRONG DATASET BIAS DETECTED:\")\n",
    "    print(f\"   1. Consider dataset-specific normalization (Z-score per dataset)\")\n",
    "    print(f\"   2. Apply domain adaptation techniques before clustering\")\n",
    "    print(f\"   3. Evaluate clustering results with stratified validation by dataset\")\n",
    "    print(f\"   4. Report dataset as a potential confounding variable\")\n",
    "    print(f\"   5. Consider training separate models per dataset or using dataset as a feature\")\n",
    "elif moderate_bias_count > 0:\n",
    "    print(f\"   ‚ö° MODERATE DATASET BIAS DETECTED:\")\n",
    "    print(f\"   1. StandardScaler normalization should suffice\")\n",
    "    print(f\"   2. Monitor cluster compositions for dataset imbalance\")\n",
    "    print(f\"   3. Validate that clusters represent genres, not datasets\")\n",
    "    print(f\"   4. Document bias levels in your report\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ NO SIGNIFICANT BIAS:\")\n",
    "    print(f\"   1. Datasets are sufficiently homogeneous for combined analysis\")\n",
    "    print(f\"   2. Proceed with standard normalization and clustering\")\n",
    "    print(f\"   3. Dataset origin unlikely to be primary clustering factor\")\n",
    "\n",
    "print(f\"\\nüìä NEXT STEPS:\")\n",
    "print(f\"   1. Apply appropriate normalization based on bias findings\")\n",
    "print(f\"   2. Proceed to PCA dimensionality reduction (Step 3)\")\n",
    "print(f\"   3. During clustering, verify that dataset != cluster\")\n",
    "print(f\"   4. Use cross-tabulation to check cluster-dataset relationships\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"‚úÖ STEP 1.6 COMPLETE: Dataset Bias Assessment Finished\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca0cd9",
   "metadata": {},
   "source": [
    "## 13. Generate Bias Report Heatmap\n",
    "\n",
    "Create a comprehensive heatmap showing all statistical test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table for heatmap\n",
    "pivot_df = bias_results_df.pivot_table(\n",
    "    index='Feature',\n",
    "    values='P-Value',\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "# Transform p-values for better visualization (log scale)\n",
    "pivot_df_log = -np.log10(pivot_df)\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(pivot_df_log, annot=True, fmt='.2f', cmap='RdYlGn_r',\n",
    "            cbar_kws={'label': '-log10(p-value)'},\n",
    "            linewidths=1, linecolor='white', ax=ax)\n",
    "\n",
    "# Add significance thresholds\n",
    "ax.axhline(y=0, color='blue', linewidth=2, linestyle='--', alpha=0.5)\n",
    "ax.text(0.5, -0.5, 'p < 0.001: Strong Bias (> 3.0)', fontsize=10, ha='center')\n",
    "ax.text(0.5, -0.8, 'p < 0.05: Moderate Bias (> 1.3)', fontsize=10, ha='center')\n",
    "\n",
    "plt.title('Dataset Bias Detection: Statistical Significance Heatmap\\n-log10(p-value) from Kruskal-Wallis Test',\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'bias_heatmap.png'), dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Saved: bias_heatmap.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
